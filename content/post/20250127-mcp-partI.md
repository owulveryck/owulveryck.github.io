---
title: "MCP Part I - Core Concepts, Past, Present And Future Of Agentic systems"
date: 2025-01-27T12:15:33+01:00
lastmod: 2025-01-27T12:15:33+01:00
images: []
draft: false
keywords: []
summary:
tags: []
categories: []
author: "Olivier Wulveryck"
comment: false
toc: true
autoCollapseToc: false
# You can also define another contentCopyright.
contentCopyright: false
reward: false
mathjax: false
---


This exploration of the Model Context Protocol (MCP) is presented in three distinct parts:

-   Part I, the current article, introduces the foundational concepts of MCP.
-   Part II will delve into a specific implementation, demonstrating a custom host leveraging Google's VertexAI API and the Gemini model.
-   Part III will showcase a practical custom server implementation tailored for a particular use case.

The parts are linked, but loosely coupled.


## About Agentic Systems

Before starting, let's pose some ubiquitous language and clarification that will be used throughout this series of articles:

An **agent** is a general concept. Is it an entity that can interact with an *environment*.
An *environment* provides informations that makes it observable by the agent. It also provides capabilities that allows the agent to *interact* with it.
By interacting with the environment, the agent will change it. Those changes provides usefulness to the agent (an agent that cannot change any environment is useless).

When talking about agent, we also often talk about autonomy. Autonomy is a variable property of an agent - it is the property the agent has to act on its own.
There can be various level of autonomu. The more autonomous the agent is, the less human interaction it requires to act.

_Note_ I won't go into details here, but do not cofound agents and workflow. A workflow is a pre-programmed execution process. It is an automated representation of a human process. See it as an execution graph. Even if one link can embed cognitive automation it is not to be confused with the concept of agentivity we are using here.

### About environments

Even if current AI (r)evolution is about the reasoning process, let's figure out the most important thing that will make those AI usefull to humankind: environments.

To be pragmatic, I will illustrate this part with the most used environment nowadays: a chat window.
In a chatbot (such as claude, gemini or chatgpt) the model is a LLM (Large Language Model) and it **generates textual** informations (it is generative AI). Its goal is to continue a prompt and fill a context window.

The context window is like a text book (of a limited size) into which your store your conversation.
The chat interface is a kind of user interface, a representation of the environment. You can write in the chat window.... and the agent can also write in this window.

_Note_ This is over simplified for the sake of the explanation. The context window could be considered as being part of the environment, but I keep it seprated to ease the explanation that will coe in part II of this series (where we will dig into the agent) 

![Diagram depicting the interaction between a user and an agentic system. The user, represented by a blue box labeled 'User', sends a query to the system via a chat window. The query is processed by a large language model (LLM), depicted as a red box labeled 'LLM'. The LLM then interacts with various tools represented by grey boxes to fulfill the user's request. The flow of information is shown with blue arrows for user input and red arrows for system output. The system's response is then returned to the user via the chat window.](/assets/MCP/partI/Image1.png)

The *environment is closed* and its boundaries are the *context window*.

As human, we are also agent. And we intact with a lot of environments.

For example, the world wide web (WWW) can be seen as an environment and the browser is the tool that allows us to interact with it. By clicking on a link, we change what is presented. 
Moreover, in the digital world, we are exposed to multiple capabilities that allows us to interact with the system - e.g. adding an item to a shopping cart or booking an hotel.

So to bring even more usefulness to the agent, we should give them the ability to interact with a wider enviromnent than the caht window.

As human, we could then delegate cognitive tasks and use them as proper assistants. We could then be free from doing toil (remember, we are talking about agent, not workflow)

![Diagram depicting the interaction between a user and an agentic system. The user, represented by a blue box labeled 'User', sends a query to the system via a chat window. The query is processed by a large language model (LLM), depicted as a red box labeled 'LLM'. The LLM then interacts with various tools represented by grey boxes to fulfill the user's request. The flow of information is shown with blue arrows for user input and red arrows for system output. The system's response is then returned to the user via the chat window.](/assets/MCP/partI/Image2.png)

The problem is therefore: how to make the agent interact with the environment... any environment.

## The solution to the problem

Giving an agent the ability to interact with a digital environment is not straightforward.
Actually, the model can understand an intention; it can more or less reason, but most of the time, the only environment it can interact with is the chat window.

Therefore we neet to provide new capabilities that it can trigger as required.

These capabilities are presented as **digital tools** and exposed **as functions**.

Each tool is then specialized to perform a certain task.

### How the agent can use the tool ?

Now the question is: how can the agent use the tool? And how does it choose the write tool if we provide many of them ?
Keep in mind that the interaction with the model is, as of today, always through natural language.

Therefore we need to setup some glue to give the agent the ability to run the tool.

![Diagram depicting the interaction between a user and an agentic system. The user, represented by a blue box labeled 'User', sends a query to the system via a chat window. The query is processed by a large language model (LLM), depicted as a red box labeled 'LLM'. The LLM then interacts with various tools represented by grey boxes to fulfill the user's request. The flow of information is shown with blue arrows for user input and red arrows for system output. The system's response is then returned to the user via the chat window.](/assets/MCP/partI/Image3.png)

Most of the generative models execution engines comes with a Software Development Kit (SDK) that allows interactin and extending the capabilities of the model under the hoow. (In the second part of this series, I will explain those concepts by implementing an agent based on Google's VertexAI services).

But this system is invasive. It requires a heavy modification of the agent in term of computer code. The tool is therefore hardcoded within the agent.

![Diagram depicting the interaction between a user and an agentic system. The user, represented by a blue box labeled 'User', sends a query to the system via a chat window. The query is processed by a large language model (LLM), depicted as a red box labeled 'LLM'. The LLM then interacts with various tools represented by grey boxes to fulfill the user's request. The flow of information is shown with blue arrows for user input and red arrows for system output. The system's response is then returned to the user via the chat window.](/assets/MCP/partI/Image4.png)

Separating the tool would provide a huge set of advantages:

- The tool as nothing to do with AI (modeling, science, and so on). It is pure software engineering. Therefore it can live its own lifecycle independently of the agent (it could be used by any model, or event by a human).
- The tool can move closer to the environment. It can act as an entry point to the enviroment. The ownership is close to the business. The business is in charge of exposing the resources of the enviroment and the actions it wants to provide to the agents.

![Diagram depicting the interaction between a user and an agentic system. The user, represented by a blue box labeled 'User', sends a query to the system via a chat window. The query is processed by a large language model (LLM), depicted as a red box labeled 'LLM'. The LLM then interacts with various tools represented by grey boxes to fulfill the user's request. The flow of information is shown with blue arrows for user input and red arrows for system output. The system's response is then returned to the user via the chat window.](/assets/MCP/partI/Image5.png)

The Web could, for example, be turned into an ecosystem of tools that could be used by any agent to perform a task. 

## Model Context Protocol as a standard

To create this ecosystem of tools that allows interaction with the most environment possible, there is a need for a standard: a proper way for the agent and the tools to communicate.

See this as a structure that standardized the communication (think about the world wide web - without HTTP/HTML, nothing would have worked the way it does nowadays). For example the standard could be a template:

```
I exposed a function {{function_name}} that does {{description}} and that requires those arguments:
- {{argument_name}} is a {{type}} that represents {{description}}
```

You get the drill. Then this description is serialized into a computer language that allows it to be transfered _over the wire_ and therefore accessible over the Internet.

This is, in essence what MCP is about: a standard of exposition and communication.

### MCP in details

So MCP is a standard to enhance the agent and give it tools that is will be able to use is out-of-the-box.

#### Ubiquitous language of MCP

MCP comes with its own vocabulary. I will expose some of its concepts here:

- The tools we are talking about are called _MCP Servers_ 
- The application running the LLM is _a host_
- The _host_ communicates with the _MCP Server_ by implementing an _MCP Client_

#### What an MCP server exposes

There is more in the MCP protocol than just a set of vocabulary. The protocol defines a set of standard types of three capabilities that a server can provide.

- **Resources**: a server can expose resources of an environment
- **Tools**: a server can provide functions to perform certain specific tasks (`add two number` of `book a room` for example)
- **Prompts**: a server can provide pre-written templates. It can feed the host with more knowledge to help him forge its reasoning.

This standard makes it easy to extend the ability of an agent.

I won't go into the details implementation of what the MCP is (this will the topic of the Part III of this series where we will talk about Remote Procedure Call, JSON and other IT topics).
I will close this article about a set of conviction I have

## Conclusions and convictions

This standard makes it easy to exetend the ability of **any** agent.
It changed the business paradigm and is, according to me, the enabler of the next digital revolution.

Ths first revolution was the Internet. Internet brought omnichannel. A business could expose its services and the users could interact with it from his/her/their coach.

![Diagram depicting the interaction between a user and an agentic system. The user, represented by a blue box labeled 'User', sends a query to the system via a chat window. The query is processed by a large language model (LLM), depicted as a red box labeled 'LLM'. The LLM then interacts with various tools represented by grey boxes to fulfill the user's request. The flow of information is shown with blue arrows for user input and red arrows for system output. The system's response is then returned to the user via the chat window.](/assets/MCP/partI/Image6.png)

The second revolution was the smartphone that brought true digital services (accessible with digits) and the nomadism: services from everywhere. But it was still the reponsibility of the user to do cognitive routing to use one service or another (_shall I book the train first, of the hotel... is it compatible with my agenda ..._)

The next revolution is that you won't do those cognitive tasks by yourself. You will delegate it to an assistant.

But which assistant will own your favors ?
The assistant that will get the most favor will win a business war: it will hold millions or even billions of optential users it can route to a business depending on the will of the model.
This is the next business eldorado: What host will be the most used, which data will it collect to enhance its usage of the better tool... the one from you favorite compagnie... or the one provided by the company that pays the most.


In the next part I will expose hot to build a host "from scratch" in a private area (to keep your data relatively safe from this). And then in the last part, I will detail an implementation of an MCP server to fulfill a use case I am working on with one of my customer regarding cyber security.
