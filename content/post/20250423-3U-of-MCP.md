---
title: "MCP's 3 U's: Making a Tool Useful, Usable, and Used by and for an LLM"
date: 2025-04-23T12:15:33+01:00
lastmod: 2025-04-23T12:15:33+01:00
images: [/assets/mcp/partI/Image5.png]
draft: false
keywords: []
summary: 
tags: []
categories: []
author: "Olivier Wulveryck"
comment: false
toc: true
autoCollapseToc: false
# You can also define another contentCopyright.
contentCopyright: false
reward: false
mathjax: false
---

Since its announcement a couple of months ago, the Model Context Protocol (MCP) has gained significant attention.

Initially, MCP served as a straightforward mechanism, essentially a plugin system, to grant Large Language Models (LLMs) the ability to interact seamlessly with their environment, thus enhancing AI assistants and agents. Applying Wardley's theory to trace the protocol's evolution, I'd argue that MCP has progressed beyond Stage I (labeled _genesis_ in the image), establishing a *certainty of solution*. Furthermore, its widespread adoption suggests it has entered Phase II (labeled _Custom Built_ on the image).

![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMFN3o1ujMDfd4y78hHCRFmPSTf9BP5C_Ej1jtEyZrmNC21aBw-18gAbVk88nKHdVa3gd_-D3z3pKKfO4Wa6XsIa1BuTkeiazqGLdu8vlUPsSaXeDgbkbvrMy3CSHlUiqk5ol1ig/s1600/Screen+Shot+2014-01-09+at+13.26.48.png)

_Note_ it is beyond the scope of this article to explain Wardley's theory. See the reference on [Simon Wardley's blog](https://blog.gardeviance.org/2014/03/on-mapping-and-evolution-axis.html) for more info)

Consequently, we're observing products *crafted with* MCP. The subsequent phase involves developing products *around* MCP.

Personally, my focus remains on exploring the protocol to identify the specific problems it can effectively address.

I previously blogged about a Proof of Concept (POC) developed during MCP's Stage I, a time when confirming the protocol's viability was paramount.

Currently, I interact with an AI that leverages various tools. My setup features middleware exposing a REST API compatible with OpenAI v1. As a user, I engage through a UI, which communicates with the middleware. The middleware, in turn, invokes the inference engine to provide input to the LLM and orchestrates calls to MCP tools in the order determined by the LLM.

Integrating MCP servers into the middleware is simple, instantly enabling them as capabilities accessible to the LLM.

The MCP protocol, along with its middleware implementation, ensures that any tool becomes *usable* by any LLM compatible with my inference engine (currently, I utilize Vertex AI from Google, with plans to incorporate support for Ollama in the future.)

This article focuses on understanding how to craft tools that fulfill the 3Us (**usable**, **useful**, **used**) from the perspective of the LLM. In this article, I will explore the notion of prompt exposition of the MCP protocol, showing why it is important to consider when moving from an MCP POC to an MCP product.

## `{JSON-RPC + NLP}`: _Organon Organ≈çn_

MCP provides an answer to the question: "_How does the user (the LLM in our case) interact with the tool?_" by offering a communication structure: JSON-RPC.

But, in fact, there are two languages involved in this communication, both stemming from the LLM trying to achieve its goal with a tool:

- JSON-RPC, as mentioned, governs tool manipulation.
- Natural Language supports *why* the user (again, the LLM) should use the tool.

Therefore, it is mandatory to have a clear description of the tool exposed through MCP, similar to proper documentation. LLMs understand our language, so we should provide them with our documentation.

Without this documentation, the tool lacks affordance and, consequently, may not be **used** by the LLM.

## Useful to ensure it is used
