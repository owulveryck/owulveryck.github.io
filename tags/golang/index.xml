<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>golang on Unladen swallow - Olivier Wulveryck</title><link>https://owulveryck.github.io/tags/golang.html</link><description>Recent content in golang on Unladen swallow - Olivier Wulveryck</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Olivier Wulveryck</copyright><lastBuildDate>Fri, 16 Aug 2019 21:25:30 +0200</lastBuildDate><atom:link href="https://owulveryck.github.io/tags/golang/index.xml" rel="self" type="application/rss+xml"/><item><title>A simple face detection utility from Python to Go</title><link>https://owulveryck.github.io/2019/08/16/a-simple-face-detection-utility-from-python-to-go.html</link><pubDate>Fri, 16 Aug 2019 21:25:30 +0200</pubDate><guid>https://owulveryck.github.io/2019/08/16/a-simple-face-detection-utility-from-python-to-go.html</guid><description>In this article, I explain how to build a tool to detect faces in a picture. This article is a sort of how-to design and implements a tool by using a neural network.
For the design part, I describe how to:
build the business model thanks to a neural network; adapt the network to the specific domain of face detection by changing its knowledge; use the resulting domain with a go-based infrastructure; code a little application in Go to communicate with the outside world.</description></item><item><title>From a project to a product: the state of onnx-go</title><link>https://owulveryck.github.io/2019/04/03/from-a-project-to-a-product-the-state-of-onnx-go.html</link><pubDate>Wed, 03 Apr 2019 20:33:42 +0200</pubDate><guid>https://owulveryck.github.io/2019/04/03/from-a-project-to-a-product-the-state-of-onnx-go.html</guid><description>&lt;script src=&#34;https://owulveryck.github.io/js/fabric.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://owulveryck.github.io/js/wasm_exec1.12.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://owulveryck.github.io/js/loader_onnx.js&#34;&gt;&lt;/script&gt;</description></item><item><title>My journey with ONNX and Go - Running the graph</title><link>https://owulveryck.github.io/2018/09/19/my-journey-with-onnx-and-go-running-the-graph.html</link><pubDate>Wed, 19 Sep 2018 08:53:09 +0200</pubDate><guid>https://owulveryck.github.io/2018/09/19/my-journey-with-onnx-and-go-running-the-graph.html</guid><description>In the previous post, I made an introduction and a POC to interact with ONNX models and Go.
I have decoded the information to reconstruct a graph. Now I propose to expand the principle and to create a proper execution backend based on Gorgonia. This post is a bit more technical than the previous one because all the concepts needed to work should be present in the last article.</description></item><item><title>My journey with ONNX and Go - The beginning</title><link>https://owulveryck.github.io/2018/08/14/my-journey-with-onnx-and-go-the-beginning.html</link><pubDate>Tue, 14 Aug 2018 20:41:30 +0200</pubDate><guid>https://owulveryck.github.io/2018/08/14/my-journey-with-onnx-and-go-the-beginning.html</guid><description>This year has started with a lot of deep thoughts about the software 2.0. My conclusion (which is slightly different from Andrej Karpathy&amp;rsquo;s consideration) is that a software 2.0 is a combination of a Neural network model and its associated weights. This is a concept; now the question is: how to materialize the idea? What artifact represents a software 2.0.
I emitted several ideas and tried one of them: to serialize the mathematical model and the weights.</description></item><item><title>Playing with Facebook&#39;s GraphQL (applied to AWS products and offers management)</title><link>https://owulveryck.github.io/2017/03/22/playing-with-facebooks-graphql-applied-to-aws-products-and-offers-management.html</link><pubDate>Wed, 22 Mar 2017 09:15:35 +0100</pubDate><guid>https://owulveryck.github.io/2017/03/22/playing-with-facebooks-graphql-applied-to-aws-products-and-offers-management.html</guid><description>About GraphQL GraphQL has been invented by Facebook for the purpose of refactoring their mobile application. Facebook had reached the limits of the standard REST API mainly because:
Getting that much information was requiring a huge amount of API endpoints The versioning of the API was counter-productive regarding Facebook&amp;rsquo;s frequents deployements. But graphql is not only a query language related to Facebook. GraphQL is not only applicable to social data.</description></item><item><title>Linda&#39;s evalc, a (tuple)space oddity</title><link>https://owulveryck.github.io/2017/03/13/lindas-evalc-a-tuplespace-oddity.html</link><pubDate>Mon, 13 Mar 2017 20:54:27 +0100</pubDate><guid>https://owulveryck.github.io/2017/03/13/lindas-evalc-a-tuplespace-oddity.html</guid><description>For a change, I will start with a good soundtrack
(youtube version for those who are spotify-less)
This is my third article about the distributed coordination language Linda.
The final target of the work is to use this coordination mechanism to deploy and maintain applications based on the description of their topology (using, for example, TOSCA as a DSL).
Last time, I introduced a lisp based language (zygomys) as an embedded programing mechanism to describe the business logic.</description></item><item><title>350000 rows, 133 cols... From a huge CSV to DynamoDB (without breaking piggy-bank).</title><link>https://owulveryck.github.io/2017/03/11/350000-rows-133-cols...-from-a-huge-csv-to-dynamodb-without-breaking-piggy-bank..html</link><pubDate>Sat, 11 Mar 2017 09:15:17 +0100</pubDate><guid>https://owulveryck.github.io/2017/03/11/350000-rows-133-cols...-from-a-huge-csv-to-dynamodb-without-breaking-piggy-bank..html</guid><description>In this post I will explain how to:
Parse a CSV file and extract only certain columns Create a table in DynamoDB Insert all the data with an adaptive algorithm in order to use the provisioned capacity Reduce the capacity once the insertion is done. Exploring the problem: AWS Billing In a previous post I explained how I was using dynamodb to store a lot of data about aws billing.</description></item><item><title>A foot in NoSQL and a toe in big data</title><link>https://owulveryck.github.io/2017/01/13/a-foot-in-nosql-and-a-toe-in-big-data.html</link><pubDate>Fri, 13 Jan 2017 22:22:46 +0100</pubDate><guid>https://owulveryck.github.io/2017/01/13/a-foot-in-nosql-and-a-toe-in-big-data.html</guid><description>The more I work with AWS, the more I understand their models. This goes far beyond the technical principles of micro service. As an example I recently had an opportunity to dig a bit into the billing process. I had an explanation given by a colleague whose understanding was more advanced than mine. In his explanation, he mentioned this blog post: New price list API.
Understanding the model By reading this post and this explanation, I understand that the offers are categorized in families (eg AmazonS3) and that an offer is composed of a set of products.</description></item><item><title>Image reKognition with a webcam, go and AWS.</title><link>https://owulveryck.github.io/2016/12/16/image-rekognition-with-a-webcam-go-and-aws..html</link><pubDate>Fri, 16 Dec 2016 14:51:18 +0100</pubDate><guid>https://owulveryck.github.io/2016/12/16/image-rekognition-with-a-webcam-go-and-aws..html</guid><description>It&amp;rsquo;s been a while since I last posted something. I will fill the gap with a quick post about rekognition.
rekognition is a service from AWS that is described as:
Deep learning-based image recognition
Search, verify, and organize millions of images
In this light post, I will present a simple method to grab a picture from my webcam, send it to rekognition and display the result.
The part of the result I will focus on is the emotion.</description></item><item><title>HTTP over UDT for inter-region file transfer</title><link>https://owulveryck.github.io/2016/10/17/http-over-udt-for-inter-region-file-transfer.html</link><pubDate>Mon, 17 Oct 2016 20:50:18 +0200</pubDate><guid>https://owulveryck.github.io/2016/10/17/http-over-udt-for-inter-region-file-transfer.html</guid><description>Introduction Transferring files between server is no big deal with nowadays network equipments. You use rsync, scp or even http to get a file from A to B.
Of course, you rely on the TCP stack so you have a decent reliability in the transport.
But TCP has its drawback, especially when it needs to go through a lot of equipments. Typically in the cloud, or over a VPN.</description></item><item><title>Getting weather data from the station to the raspberry</title><link>https://owulveryck.github.io/2016/08/29/getting-weather-data-from-the-station-to-the-raspberry.html</link><pubDate>Mon, 29 Aug 2016 21:58:17 +0200</pubDate><guid>https://owulveryck.github.io/2016/08/29/getting-weather-data-from-the-station-to-the-raspberry.html</guid><description>Introduction A bunch of friends/colleagues offered me a raspberry pi 3. It may become my VPN gateway, or my firewall, or the brain of my CCTV, or maybe the center of an alarm&amp;hellip;. Maybe a spotify player&amp;hellip;
Anyway, I have installed raspbian and I&amp;rsquo;m now playing with it.
Yesterday evening, as I was about to go to bed, I&amp;rsquo;ve had a very bad idea&amp;hellip; I&amp;rsquo;ve linked together my rpi and my Oregon Weather Station.</description></item><item><title>Websockets, Reveal.js, D3 and GO for a dynamic keynote</title><link>https://owulveryck.github.io/2016/06/23/websockets-reveal.js-d3-and-go-for-a-dynamic-keynote.html</link><pubDate>Thu, 23 Jun 2016 15:32:54 +0200</pubDate><guid>https://owulveryck.github.io/2016/06/23/websockets-reveal.js-d3-and-go-for-a-dynamic-keynote.html</guid><description>the goal As all my peers, I have the opportunity to talk about different technological aspects. As all my peers, I&amp;rsquo;m asked to present a bunch of slides (powerpoint or keynote, or whatever).
In this post I won&amp;rsquo;t dig into what&amp;rsquo;s good or not to put in a presentation, and if that&amp;rsquo;s what interest you, I recommend you to take a look at Garr Reynold&amp;rsquo;s tips and tricks.
Steve Jobs said:</description></item><item><title>Orchestrate a digraph with goroutine, a concurrent orchestrator</title><link>https://owulveryck.github.io/2015/12/02/orchestrate-a-digraph-with-goroutine-a-concurrent-orchestrator.html</link><pubDate>Wed, 02 Dec 2015 14:24:21 +0000</pubDate><guid>https://owulveryck.github.io/2015/12/02/orchestrate-a-digraph-with-goroutine-a-concurrent-orchestrator.html</guid><description>I&amp;rsquo;ve read a lot about graph theory recently. They have changed the world a lot. From the simple representation to Bayesian network via Markov chains, the applications are numerous.
Today I would like to imagine a graph as a workflow of execution. Every node would be considered as runnable. And every edge would be a dependency.
It is an important framework that may be used to as an orchestrator for any model, and of course I am a lot thinkingabout TOSCA</description></item><item><title>TOSCA lifecycle as a digraph</title><link>https://owulveryck.github.io/2015/11/20/tosca-lifecycle-as-a-digraph.html</link><pubDate>Fri, 20 Nov 2015 10:09:30 +0000</pubDate><guid>https://owulveryck.github.io/2015/11/20/tosca-lifecycle-as-a-digraph.html</guid><description>About TOSCA The TOSCA acronym stands for Topology and Orchestration Specification for Cloud Applications. It&amp;rsquo;s an OASIS standard.
The purpose of the TOSCA project is to represent an application by its topology and formalize it using the TOSCA grammar.
The [TOSCA-Simple-Profile-YAML-v1.0] current specification in YAML introduces the following concepts.
TOSCA YAML service template: A YAML document artifact containing a (TOSCA) service template that represents a Cloud application. TOSCA processor: An engine or tool that is capable of parsing and interpreting a TOSCA YAML service template for a particular purpose.</description></item></channel></rss>